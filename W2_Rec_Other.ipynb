{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E93_Kw2nZUQ0"
      },
      "source": [
        "# 1. Load Trained SGLD Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtiaD_GgOQWj",
        "outputId": "d122e922-cf63-4fec-ac62-8631d1d5faea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "ðŸ“‚ Files in dataset directory: ['README', 'combined_data_3.txt', 'combined_data_4.txt', 'probe.txt', 'qualifying.txt', 'combined_data_1.txt', 'movie_titles.csv', 'combined_data_2.txt', 'combined_data_1_fixed.csv', 'movies_data_fixed.csv', 'sparse_matrix.npz', 'U_sgld.npy', 'V_sgld.npy', 'U_sgd.npy', 'V_sgd.npy', 'U_als.npy', 'V_als.npy']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Drive Mount\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define Dataset Path\n",
        "dataset_path = \"/content/drive/MyDrive/Netflix_Dataset/\"\n",
        "\n",
        "# Check Files in Dataset Folder\n",
        "print(\"ðŸ“‚ Files in dataset directory:\", os.listdir(dataset_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4-F4D6gZacO",
        "outputId": "70016e17-3e1e-4872-e4cf-76176b6836a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SGLD RMSE: 0.9671\n",
            " SGLD MAE: 0.7289\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "from scipy.sparse import load_npz\n",
        "\n",
        "#  Load Ground Truth Ratings (Sparse Matrix)\n",
        "sparse_matrix_path = \"/content/drive/MyDrive/Netflix_Dataset/sparse_matrix.npz\"\n",
        "rating_matrix_sparse = load_npz(sparse_matrix_path)\n",
        "\n",
        "#  Load SGLD-trained matrices\n",
        "U_sgld = np.load(\"/content/drive/MyDrive/Netflix_Dataset/U_sgld.npy\")\n",
        "V_sgld = np.load(\"/content/drive/MyDrive/Netflix_Dataset/V_sgld.npy\")\n",
        "\n",
        "#  Extract non-zero indices (Only compare known ratings)\n",
        "user_indices, movie_indices = rating_matrix_sparse.nonzero()\n",
        "actual_ratings = rating_matrix_sparse.data  # ì‹¤ì œ í‰ì \n",
        "\n",
        "# Predicted ratings using the dot product of U and V\n",
        "predicted_ratings = np.sum(U_sgld[user_indices] * V_sgld[movie_indices], axis=1)\n",
        "\n",
        "# RMSE (Root Mean Squared Error)\n",
        "rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
        "\n",
        "# MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(f\" SGLD RMSE: {rmse:.4f}\")\n",
        "print(f\" SGLD MAE: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4DW7VHQlmz",
        "outputId": "359537db-d6d1-4946-e6db-c86c967f30c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SGLD Precision@10: 0.0250\n"
          ]
        }
      ],
      "source": [
        "def precision_at_k(U, V, rating_matrix_sparse, k=10):\n",
        "    \"\"\"\n",
        "    Precision@K evaluation function:\n",
        "    - Measures how many of the top-rated movies by the user are included in the recommended list.\n",
        "    \"\"\"\n",
        "    user_indices, movie_indices = rating_matrix_sparse.nonzero()\n",
        "    actual_ratings = rating_matrix_sparse.toarray()\n",
        "\n",
        "    precision_scores = []\n",
        "\n",
        "    for user_id in np.unique(user_indices):\n",
        "        # Compute predicted ratings for the user\n",
        "        predicted_scores = np.dot(U[user_id], V.T)\n",
        "\n",
        "        # Retrieve movies that the user rated highly (rating â‰¥ 4)\n",
        "        actual_top_movies = set(np.where(actual_ratings[user_id] >= 4)[0])\n",
        "\n",
        "        # Recommend the top K movies based on predicted ratings\n",
        "        recommended_top_movies = set(np.argsort(predicted_scores)[-k:])\n",
        "\n",
        "        # Calculate Precision\n",
        "        precision = len(actual_top_movies & recommended_top_movies) / k\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "    return np.mean(precision_scores)\n",
        "\n",
        "\n",
        "# Compute Precision@10\n",
        "precision_sgld = precision_at_k(U_sgld, V_sgld, rating_matrix_sparse, k=10)\n",
        "print(f\"SGLD Precision@10: {precision_sgld:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h09HjwJKZ_lr"
      },
      "source": [
        "# âœ… Other Model In processing\n",
        "\n",
        "## 1. SGD (Stochastic Gradient Descent)\n",
        "\n",
        "\n",
        "## 2. ALS (Alternating Least Squares)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvZDLB9VZ-EG",
        "outputId": "2440cc74-1bca-4005-a123-c30c705dd939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Sparse matrix loaded! Shape: (470758, 4499)\n",
            "âœ… SGD Epoch 1/10 completed.\n",
            "âœ… SGD Epoch 2/10 completed.\n",
            "âœ… SGD Epoch 3/10 completed.\n",
            "âœ… SGD Epoch 4/10 completed.\n",
            "âœ… SGD Epoch 5/10 completed.\n",
            "âœ… SGD Epoch 6/10 completed.\n",
            "âœ… SGD Epoch 7/10 completed.\n",
            "âœ… SGD Epoch 8/10 completed.\n",
            "âœ… SGD Epoch 9/10 completed.\n",
            "âœ… SGD Epoch 10/10 completed.\n",
            "ðŸŽ¯ SGD Training Completed in 201.45 seconds.\n",
            "âœ… ALS Epoch 1/10 completed.\n",
            "âœ… ALS Epoch 2/10 completed.\n",
            "âœ… ALS Epoch 3/10 completed.\n",
            "âœ… ALS Epoch 4/10 completed.\n",
            "âœ… ALS Epoch 5/10 completed.\n",
            "âœ… ALS Epoch 6/10 completed.\n",
            "âœ… ALS Epoch 7/10 completed.\n",
            "âœ… ALS Epoch 8/10 completed.\n",
            "âœ… ALS Epoch 9/10 completed.\n",
            "âœ… ALS Epoch 10/10 completed.\n",
            "ðŸŽ¯ ALS Training Completed in 5807.02 seconds.\n",
            "ðŸ“Š SGD RMSE: 0.6496, MAE: 0.4992\n",
            "ðŸ“Š ALS RMSE: 0.5274, MAE: 0.3781\n",
            "Models saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# 1. Load Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from scipy.sparse import load_npz, csr_matrix\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# 2. Mount Google Drive and Load Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Netflix_Dataset/\"\n",
        "sparse_matrix_path = dataset_path + \"sparse_matrix.npz\"\n",
        "\n",
        "# 3. Load Sparse Matrix\n",
        "rating_matrix_sparse = load_npz(sparse_matrix_path)\n",
        "rating_matrix_sparse = csr_matrix(rating_matrix_sparse)  # Conversion if needed\n",
        "\n",
        "print(f\"âœ… Sparse matrix loaded! Shape: {rating_matrix_sparse.shape}\")\n",
        "\n",
        "# 4. Check Dataset Information\n",
        "num_users, num_movies = rating_matrix_sparse.shape\n",
        "latent_dim = 50  # Number of latent dimensions\n",
        "\n",
        "# 5. SGD Training Function\n",
        "def sgd_train(U, V, rating_matrix_sparse, learning_rate=0.01, epochs=10, batch_size=5000):\n",
        "    \"\"\"\n",
        "    Stochastic Gradient Descent (SGD) for Matrix Factorization\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    user_indices, movie_indices = rating_matrix_sparse.nonzero()\n",
        "    ratings = rating_matrix_sparse.data\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        shuffled_indices = np.random.permutation(len(user_indices))\n",
        "\n",
        "        for i in range(0, len(shuffled_indices), batch_size):\n",
        "            batch_indices = shuffled_indices[i : i + batch_size]\n",
        "\n",
        "            # Prepare Mini-batch Data\n",
        "            user_batch = user_indices[batch_indices]\n",
        "            movie_batch = movie_indices[batch_indices]\n",
        "            rating_batch = ratings[batch_indices]\n",
        "\n",
        "            # Compute Predictions and Errors\n",
        "            pred_batch = np.sum(U[user_batch] * V[movie_batch], axis=1)\n",
        "            error_batch = rating_batch - pred_batch\n",
        "\n",
        "            # Gradient Descent Update\n",
        "            grad_U = -error_batch[:, np.newaxis] * V[movie_batch]\n",
        "            grad_V = -error_batch[:, np.newaxis] * U[user_batch]\n",
        "\n",
        "            U[user_batch] -= learning_rate * grad_U\n",
        "            V[movie_batch] -= learning_rate * grad_V\n",
        "\n",
        "        print(f\"âœ… SGD Epoch {epoch+1}/{epochs} completed.\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"ðŸŽ¯ SGD Training Completed in {elapsed_time:.2f} seconds.\")\n",
        "    return U, V\n",
        "\n",
        "# 6. ALS Training Function\n",
        "def als_train(rating_matrix_sparse, latent_dim=50, epochs=10, reg_lambda=0.1):\n",
        "    \"\"\"\n",
        "    Alternating Least Squares (ALS) for Matrix Factorization\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    num_users, num_movies = rating_matrix_sparse.shape\n",
        "\n",
        "    #  Random Initialization\n",
        "    U = np.random.normal(0, 0.1, (num_users, latent_dim))\n",
        "    V = np.random.normal(0, 0.1, (num_movies, latent_dim))\n",
        "\n",
        "    # ALS Iterative Optimization\n",
        "    for epoch in range(epochs):\n",
        "        # Update User Matrix U\n",
        "        for u in range(num_users):\n",
        "            idx = rating_matrix_sparse[u, :].nonzero()[1]\n",
        "            if len(idx) == 0:\n",
        "                continue\n",
        "            V_sub = V[idx]\n",
        "            ratings = rating_matrix_sparse[u, idx].toarray().flatten()\n",
        "            U[u] = np.linalg.solve(V_sub.T @ V_sub + reg_lambda * np.eye(latent_dim), V_sub.T @ ratings)\n",
        "\n",
        "        # Update Movie Matrix V\n",
        "        for v in range(num_movies):\n",
        "            idx = rating_matrix_sparse[:, v].nonzero()[0]\n",
        "            if len(idx) == 0:\n",
        "                continue\n",
        "            U_sub = U[idx]\n",
        "            ratings = rating_matrix_sparse[idx, v].toarray().flatten()\n",
        "            V[v] = np.linalg.solve(U_sub.T @ U_sub + reg_lambda * np.eye(latent_dim), U_sub.T @ ratings)\n",
        "\n",
        "        print(f\" ALS Epoch {epoch+1}/{epochs} completed.\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\" ALS Training Completed in {elapsed_time:.2f} seconds.\")\n",
        "    return U, V\n",
        "\n",
        "# 7. Execute Model Training\n",
        "#  Run SGD\n",
        "U_sgd = np.random.normal(0, 0.1, (num_users, latent_dim))\n",
        "V_sgd = np.random.normal(0, 0.1, (num_movies, latent_dim))\n",
        "U_sgd, V_sgd = sgd_train(U_sgd, V_sgd, rating_matrix_sparse)\n",
        "\n",
        "#  Run ALS\n",
        "U_als, V_als = als_train(rating_matrix_sparse)\n",
        "\n",
        "# 8. RMSE and MAE Evaluation Function\n",
        "def evaluate_model(U, V, rating_matrix_sparse):\n",
        "    user_indices, movie_indices = rating_matrix_sparse.nonzero()\n",
        "    ratings = rating_matrix_sparse.data\n",
        "\n",
        "    pred_ratings = np.sum(U[user_indices] * V[movie_indices], axis=1)\n",
        "    rmse = np.sqrt(mean_squared_error(ratings, pred_ratings))\n",
        "    mae = mean_absolute_error(ratings, pred_ratings)\n",
        "\n",
        "    return rmse, mae\n",
        "\n",
        "# 9. Evaluate Model Performance\n",
        "rmse_sgd, mae_sgd = evaluate_model(U_sgd, V_sgd, rating_matrix_sparse)\n",
        "rmse_als, mae_als = evaluate_model(U_als, V_als, rating_matrix_sparse)\n",
        "\n",
        "print(f\" SGD RMSE: {rmse_sgd:.4f}, MAE: {mae_sgd:.4f}\")\n",
        "print(f\" ALS RMSE: {rmse_als:.4f}, MAE: {mae_als:.4f}\")\n",
        "\n",
        "# 10. Save Trained Models\n",
        "np.save(dataset_path + \"U_sgd.npy\", U_sgd)\n",
        "np.save(dataset_path + \"V_sgd.npy\", V_sgd)\n",
        "np.save(dataset_path + \"U_als.npy\", U_als)\n",
        "np.save(dataset_path + \"V_als.npy\", V_als)\n",
        "\n",
        "print(\"Models saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}