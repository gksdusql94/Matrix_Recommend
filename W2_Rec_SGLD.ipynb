{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load Sparse_matrix\n"
      ],
      "metadata": {
        "id": "E93_Kw2nZUQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Netflix_Dataset/\"\n",
        "print(\"üìÇ Files in dataset directory:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "id": "K4-F4D6gZacO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ea56f0-27fb-4538-8286-0bda0ea6b89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "üìÇ Files in dataset directory: ['README', 'combined_data_3.txt', 'combined_data_4.txt', 'probe.txt', 'qualifying.txt', 'combined_data_1.txt', 'movie_titles.csv', 'combined_data_2.txt', 'combined_data_1_fixed.csv', 'movies_data_fixed.csv', 'sparse_matrix.npz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import load_npz\n",
        "\n",
        "# Load Sparse_matrix\n",
        "sparse_matrix_path = \"/content/drive/MyDrive/Netflix_Dataset/sparse_matrix.npz\"\n",
        "rating_matrix_sparse = load_npz(sparse_matrix_path)\n",
        "\n",
        "print(\"Sparse matrix successfully loaded!\")\n",
        "print(f\"Matrix shape: {rating_matrix_sparse.shape}\")  # (num_users, num_movies)"
      ],
      "metadata": {
        "id": "MxUOY3VcMAtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7fe731-5d63-4689-d6b7-aaf18828448f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse matrix successfully loaded!\n",
            "Matrix shape: (470758, 4499)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Initialize User Matrix (U) & Movie Matrix (V)\n",
        "\n",
        "‚úîÔ∏è U = User Preferences Matrix (Users √ó Latent Features)\n",
        "\n",
        "‚úîÔ∏è V = Movie Features Matrix (Movies √ó Latent Features)\n",
        "\n",
        "During training, U and V are optimized to capture hidden patterns in the user-movie interactions.\n",
        "\n",
        "Since there is no prior information at the beginning, we initialize them with random values."
      ],
      "metadata": {
        "id": "h09HjwJKZ_lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the number of latent factors (feature dimensions)\n",
        "latent_dim = 50  # This can be adjusted\n",
        "\n",
        "# Get the number of users and movies from the sparse matrix\n",
        "num_users, num_movies = rating_matrix_sparse.shape\n",
        "\n",
        "# Initialize user matrix (U) and movie matrix (V) with random values\n",
        "U = np.random.normal(0, 0.1, (num_users, latent_dim))  # User matrix\n",
        "V = np.random.normal(0, 0.1, (num_movies, latent_dim))  # Movie matrix\n",
        "\n",
        "print(f\"‚úÖ Initialized User-Movie Matrices: U={U.shape}, V={V.shape}\")"
      ],
      "metadata": {
        "id": "HvZDLB9VZ-EG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28aeabe7-cd10-4e0c-b085-f77a169e503b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Initialized User-Movie Matrices: U=(470758, 50), V=(4499, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: SGLD Optimization Function (Utilizing Vectorized Operations)\n",
        "The traditional SGD (Stochastic Gradient Descent) method often relies on loops, which makes it slow. To improve efficiency, this function utilizes vectorized operations to accelerate computations"
      ],
      "metadata": {
        "id": "0QI06wF-bZ8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgld_update(U, V, rating_matrix_sparse, learning_rate=0.01, noise_scale=0.1, batch_size=5000, epoch=1):\n",
        "    \"\"\"\n",
        "    Perform SGLD update using vectorized operations for speed improvement.\n",
        "    - Utilizes sparse matrix directly (avoids dense conversion)\n",
        "    - Implements efficient mini-batch updates\n",
        "    - Reduces the number of Python loops for faster computation\n",
        "    \"\"\"\n",
        "    adjusted_lr = learning_rate / (1 + 0.01 * epoch)  # Learning rate decay\n",
        "\n",
        "    #  Get non-zero indices from the sparse matrix (User-Movie interactions)\n",
        "    user_indices, movie_indices = rating_matrix_sparse.nonzero()\n",
        "    ratings = rating_matrix_sparse.data  # Extract only non-zero values\n",
        "    num_samples = len(user_indices)\n",
        "\n",
        "    #  Apply mini-batch sampling (random selection of batch-sized samples)\n",
        "    shuffled_indices = np.random.permutation(num_samples)\n",
        "\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        batch_indices = shuffled_indices[i : i + batch_size]\n",
        "\n",
        "        #  Process in parallel using vectorized operations\n",
        "        user_batch = user_indices[batch_indices]\n",
        "        movie_batch = movie_indices[batch_indices]\n",
        "        rating_batch = ratings[batch_indices]\n",
        "\n",
        "        #  Compute predicted values\n",
        "        pred_batch = np.sum(U[user_batch] * V[movie_batch], axis=1)\n",
        "        error_batch = rating_batch - pred_batch\n",
        "\n",
        "        #  Compute gradients (apply vectorized operations)\n",
        "        grad_U = (-error_batch[:, np.newaxis] * V[movie_batch]) + noise_scale * np.random.normal(size=U[user_batch].shape)\n",
        "        grad_V = (-error_batch[:, np.newaxis] * U[user_batch]) + noise_scale * np.random.normal(size=V[movie_batch].shape)\n",
        "\n",
        "        #  Apply Gradient Clipping (Ensure stable training)\n",
        "        grad_U = np.clip(grad_U, -0.1, 0.1)\n",
        "        grad_V = np.clip(grad_V, -0.1, 0.1)\n",
        "\n",
        "        #  Apply batch updates using vectorized operations\n",
        "        U[user_batch] -= adjusted_lr * grad_U\n",
        "        V[movie_batch] -= adjusted_lr * grad_V\n",
        "\n",
        "    return U, V\n"
      ],
      "metadata": {
        "id": "LmE0AtiKM0Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, it directly processes sparse matrices, reducing memory usage and enabling more efficient training on large datasets.\n",
        "Mini-batch training is implemented, allowing multiple samples to be processed in parallel, which enhances training stability and speed.\n",
        "Gradient Clipping prevents excessively large updates, ensuring stable training throughout the learning process"
      ],
      "metadata": {
        "id": "yMGY7sDFbsIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.01\n",
        "noise_scale = 0.1  # Adjust this value for stronger Differential Privacy\n",
        "batch_size = 5000  # Increase mini-batch size for better efficiency\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    U, V = sgld_update(U, V, rating_matrix_sparse, learning_rate, noise_scale, batch_size, epoch=epoch)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"‚úÖ Epoch {epoch+1}/{num_epochs} completed in {elapsed_time:.2f} seconds.\")\n",
        "\n",
        "print(\"üéâ Optimized SGLD-based Matrix Factorization Training Completed!\")\n"
      ],
      "metadata": {
        "id": "JvnJnEv1M2Lb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a972288-4bd4-4187-9983-a53003d50bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 1/10 completed in 119.05 seconds.\n",
            "‚úÖ Epoch 2/10 completed in 119.97 seconds.\n",
            "‚úÖ Epoch 3/10 completed in 121.34 seconds.\n",
            "‚úÖ Epoch 4/10 completed in 121.20 seconds.\n",
            "‚úÖ Epoch 5/10 completed in 121.29 seconds.\n",
            "‚úÖ Epoch 6/10 completed in 119.46 seconds.\n",
            "‚úÖ Epoch 7/10 completed in 118.92 seconds.\n",
            "‚úÖ Epoch 8/10 completed in 119.35 seconds.\n",
            "‚úÖ Epoch 9/10 completed in 118.71 seconds.\n",
            "‚úÖ Epoch 10/10 completed in 118.53 seconds.\n",
            "üéâ Optimized SGLD-based Matrix Factorization Training Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(U, V, rating_matrix_sparse):\n",
        "    \"\"\"\n",
        "    Compute RMSE & MAE for the trained model.\n",
        "    \"\"\"\n",
        "    user_indices, movie_indices = rating_matrix_sparse.nonzero()\n",
        "    true_ratings = rating_matrix_sparse.data  # Actual ratings\n",
        "\n",
        "    # Compute predicted ratings\n",
        "    predicted_ratings = np.sum(U[user_indices] * V[movie_indices], axis=1)\n",
        "\n",
        "    # Compute RMSE & MAE\n",
        "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
        "\n",
        "    print(f\"üìä RMSE: {rmse:.4f}\")\n",
        "    print(f\"üìä MAE: {mae:.4f}\")\n",
        "\n",
        "# Run evaluation\n",
        "evaluate_model(U, V, rating_matrix_sparse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVCb5qGxgRZb",
        "outputId": "911bfe8c-97f6-455d-fee9-d51c6ad22843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä RMSE: 0.9671\n",
            "üìä MAE: 0.7289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained matrices\n",
        "np.save(\"/content/drive/MyDrive/Netflix_Dataset/U_sgld.npy\", U)\n",
        "np.save(\"/content/drive/MyDrive/Netflix_Dataset/V_sgld.npy\", V)\n",
        "\n",
        "print(\"‚úÖ Trained matrices (U, V) saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wFllVtygUiK",
        "outputId": "4af3fb6d-322e-4475-9dcb-18a0162307da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Trained matrices (U, V) saved successfully!\n"
          ]
        }
      ]
    }
  ]
}